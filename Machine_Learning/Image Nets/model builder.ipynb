{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdf5 is not supported on this machine (please install/reinstall h5py for optimal experience)\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "import tensorflow as tf\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "from tflearn.layers.estimator import regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:1\n",
      "INFO:root:2\n",
      "WARNING:root:3\n",
      "CRITICAL:root:4\n",
      "ERROR:root:5\n"
     ]
    }
   ],
   "source": [
    "logging.debug(1)\n",
    "logging.info(2)\n",
    "logging.warning(3)\n",
    "logging.critical(4)\n",
    "logging.error(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "TRAIN_DIR = \"../Cat_Dog/train\"\n",
    "\n",
    "def convert_to_one_hot_label(img_name):\n",
    "    label = img_name.split(\".\")[0]\n",
    "    return [1, 0] if label == \"cat\" else [0, 1]\n",
    "\n",
    "def load_train_data(resize_pics=(227, 227)):\n",
    "    width = resize_pics[0]\n",
    "    height = resize_pics[1]\n",
    "    FILE_NAME = \"train_data_{}x{}.npy\".format(width, height)\n",
    "    if os.path.exists(FILE_NAME):\n",
    "        logging.info(\"load train data\")\n",
    "        train_data = np.load(FILE_NAME)\n",
    "    else:\n",
    "        logging.info(\"create train data\")\n",
    "        train_data = []\n",
    "        for img_name in tqdm(os.listdir(TRAIN_DIR)):\n",
    "            one_hot_label = convert_to_one_hot_label(img_name)\n",
    "            path = os.path.join(TRAIN_DIR, img_name)\n",
    "            img = cv2.imread(path)\n",
    "            img = cv2.resize(img, (width, height))\n",
    "            train_data.append([img, np.array(one_hot_label)])\n",
    "        logging.info(\"finish load to memory\")\n",
    "        np.random.shuffle(train_data)\n",
    "        logging.info(\"finish shuffle\")\n",
    "        np.save(FILE_NAME, train_data)\n",
    "        logging.info(\"finish save to file\")\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:load train data\n"
     ]
    }
   ],
   "source": [
    "train_data = load_train_data(resize_pics=(227, 227))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 227, 227, 3), (25000, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = train_data[:, 0], train_data[:, 1]\n",
    "X = np.array([i for i in X])\n",
    "Y = np.array([i for i in Y])\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"AlexNet_basic\"\n",
    "NUM_CLASS = 2  # Cat, Dog\n",
    "\n",
    "def alexnet(num_class):\n",
    "    # Building 'AlexNet'\n",
    "    network = input_data(shape=[None, 227, 227, 3])\n",
    "    network = conv_2d(network, 96, 11, strides=4, activation='relu')\n",
    "    network = max_pool_2d(network, 3, strides=2)\n",
    "    network = local_response_normalization(network)\n",
    "    network = conv_2d(network, 256, 5, activation='relu')\n",
    "    network = max_pool_2d(network, 3, strides=2)\n",
    "    network = local_response_normalization(network)\n",
    "    network = conv_2d(network, 384, 3, activation='relu')\n",
    "    network = conv_2d(network, 384, 3, activation='relu')\n",
    "    network = conv_2d(network, 256, 3, activation='relu')\n",
    "    network = max_pool_2d(network, 3, strides=2)\n",
    "    network = local_response_normalization(network)\n",
    "    network = fully_connected(network, 4096, activation='tanh')\n",
    "    network = dropout(network, 0.5)\n",
    "    network = fully_connected(network, 4096, activation='tanh')\n",
    "    network = dropout(network, 0.5)\n",
    "    network = fully_connected(network, num_class, activation='softmax')\n",
    "    network = regression(network, optimizer='momentum',\n",
    "                         loss='categorical_crossentropy',\n",
    "                         learning_rate=0.001)\n",
    "    \n",
    "    return network\n",
    "\n",
    "# Training\n",
    "model = tflearn.DNN(alexnet(NUM_CLASS), checkpoint_path='model_{}'.format(MODEL_NAME),\n",
    "                    max_checkpoints=5, tensorboard_verbose=3, tensorboard_dir=\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(X, Y, n_epoch=10, validation_set=0.1, shuffle=True,\n",
    "              show_metric=True, batch_size=64, snapshot_step=500,\n",
    "              snapshot_epoch=False, run_id=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:create train data\n",
      "100%|█████████████████████████████████| 25000/25000 [04:52<00:00, 84.22it/s]\n",
      "INFO:root:finish load to memory\n",
      "INFO:root:finish shuffle\n",
      "INFO:root:finish save to file\n"
     ]
    }
   ],
   "source": [
    "train_data = load_train_data(resize_pics=(128, 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = np.array(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 128, 128, 3), (25000, 2))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = train_data[:, 0], train_data[:, 1]\n",
    "X = np.array([i for i in X])\n",
    "Y = np.array([i for i in Y])\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"AlexNet_half\"\n",
    "NUM_CLASS = 2  # Cat, Dog\n",
    "tf.reset_default_graph()\n",
    "\n",
    "def alexnet(num_class):\n",
    "    # Building 'AlexNet'\n",
    "    network = input_data(shape=[None, 128, 128, 3])\n",
    "    network = conv_2d(network, 96, 11, strides=4, activation='relu')\n",
    "    network = max_pool_2d(network, 3, strides=2)\n",
    "    network = local_response_normalization(network)\n",
    "    network = conv_2d(network, 256, 5, activation='relu')\n",
    "    network = max_pool_2d(network, 3, strides=2)\n",
    "    network = local_response_normalization(network)\n",
    "    network = conv_2d(network, 384, 3, activation='relu')\n",
    "    network = conv_2d(network, 384, 3, activation='relu')\n",
    "    network = conv_2d(network, 256, 3, activation='relu')\n",
    "    network = max_pool_2d(network, 3, strides=2)\n",
    "    network = local_response_normalization(network)\n",
    "    network = fully_connected(network, 1024, activation='tanh')\n",
    "    network = dropout(network, 0.5)\n",
    "    network = fully_connected(network, 1024, activation='tanh')\n",
    "    network = dropout(network, 0.5)\n",
    "    network = fully_connected(network, num_class, activation='softmax')\n",
    "    network = regression(network, optimizer='momentum',\n",
    "                         loss='categorical_crossentropy',\n",
    "                         learning_rate=0.001)\n",
    "    \n",
    "    return network\n",
    "\n",
    "# Training\n",
    "model = tflearn.DNN(alexnet(NUM_CLASS), checkpoint_path='checkpoint/model_{}'.format(MODEL_NAME),\n",
    "                    max_checkpoints=5, tensorboard_verbose=0, tensorboard_dir=\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7040  | total loss: 0.72174 | time: 38.292s\n",
      "| Momentum | epoch: 010 | loss: 0.72174 - acc: 0.4815 -- iter: 22500/22500\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, Y, n_epoch=10, validation_set=0.1, shuffle=True,\n",
    "              show_metric=True, batch_size=32, snapshot_step=200,\n",
    "              snapshot_epoch=False, run_id=MODEL_NAME)\n",
    "model.save(\"model/\" + MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3520  | total loss: 0.50641 | time: 34.444s\n",
      "| Momentum | epoch: 010 | loss: 0.50641 - acc: 0.7509 -- iter: 22500/22500\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"AlexNet_half_2\"\n",
    "NUM_CLASS = 2  # Cat, Dog\n",
    "tf.reset_default_graph()\n",
    "\n",
    "def alexnet(num_class):\n",
    "    # Building 'AlexNet'\n",
    "    network = input_data(shape=[None, 128, 128, 3])\n",
    "    network = conv_2d(network, 96, 11, strides=4, activation='relu')\n",
    "    network = max_pool_2d(network, 3, strides=2)\n",
    "    network = local_response_normalization(network)\n",
    "    network = conv_2d(network, 256, 5, activation='relu')\n",
    "    network = max_pool_2d(network, 3, strides=2)\n",
    "    network = local_response_normalization(network)\n",
    "    network = conv_2d(network, 384, 3, activation='relu')\n",
    "    network = conv_2d(network, 384, 3, activation='relu')\n",
    "    network = conv_2d(network, 256, 3, activation='relu')\n",
    "    network = max_pool_2d(network, 3, strides=2)\n",
    "    network = local_response_normalization(network)\n",
    "    network = fully_connected(network, 4096, activation='tanh')\n",
    "    network = dropout(network, 0.5)\n",
    "    network = fully_connected(network, 4096, activation='tanh')\n",
    "    network = dropout(network, 0.5)\n",
    "    network = fully_connected(network, num_class, activation='softmax')\n",
    "    network = regression(network, optimizer='momentum',\n",
    "                         loss='categorical_crossentropy',\n",
    "                         learning_rate=0.001)\n",
    "    \n",
    "    return network\n",
    "\n",
    "# Training\n",
    "model = tflearn.DNN(alexnet(NUM_CLASS), checkpoint_path='checkpoint/model_{}'.format(MODEL_NAME),\n",
    "                    max_checkpoints=5, tensorboard_verbose=0, tensorboard_dir=\"log\")\n",
    "\n",
    "model.fit(X, Y, n_epoch=10, validation_set=0.1, shuffle=True,\n",
    "              show_metric=True, batch_size=64, snapshot_step=200,\n",
    "              snapshot_epoch=False, run_id=MODEL_NAME)\n",
    "model.save(\"model/\" + MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7040  | total loss: 0.26386 | time: 35.391s\n",
      "| Momentum | epoch: 020 | loss: 0.26386 - acc: 0.8842 -- iter: 22500/22500\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, Y, n_epoch=10, validation_set=0.1, shuffle=True,\n",
    "              show_metric=True, batch_size=64, snapshot_step=200,\n",
    "              snapshot_epoch=False, run_id=MODEL_NAME)\n",
    "model.save(\"model/\" + MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:load train data\n"
     ]
    }
   ],
   "source": [
    "train_data = load_train_data(resize_pics=(227, 227))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 227, 227, 3), (25000, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = train_data[:, 0], train_data[:, 1]\n",
    "X = np.array([i for i in X])\n",
    "Y = np.array([i for i in Y])\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"VGG16_basic\"\n",
    "NUM_CLASS = 2\n",
    "def vgg16(num_class):\n",
    "    # Building 'VGG Network'\n",
    "    x = tflearn.input_data(shape=[None, 227, 227, 3], name='input')  # 원래는 224x224\n",
    "    x = tflearn.conv_2d(x, 64, 3, activation='relu', scope='conv1_1')\n",
    "    x = tflearn.conv_2d(x, 64, 3, activation='relu', scope='conv1_2')\n",
    "    x = tflearn.max_pool_2d(x, 2, strides=2, name='maxpool1')\n",
    "\n",
    "    x = tflearn.conv_2d(x, 128, 3, activation='relu', scope='conv2_1')\n",
    "    x = tflearn.conv_2d(x, 128, 3, activation='relu', scope='conv2_2')\n",
    "    x = tflearn.max_pool_2d(x, 2, strides=2, name='maxpool2')\n",
    "\n",
    "    x = tflearn.conv_2d(x, 256, 3, activation='relu', scope='conv3_1')\n",
    "    x = tflearn.conv_2d(x, 256, 3, activation='relu', scope='conv3_2')\n",
    "    x = tflearn.conv_2d(x, 256, 3, activation='relu', scope='conv3_3')\n",
    "    x = tflearn.max_pool_2d(x, 2, strides=2, name='maxpool3')\n",
    "\n",
    "    x = tflearn.conv_2d(x, 512, 3, activation='relu', scope='conv4_1')\n",
    "    x = tflearn.conv_2d(x, 512, 3, activation='relu', scope='conv4_2')\n",
    "    x = tflearn.conv_2d(x, 512, 3, activation='relu', scope='conv4_3')\n",
    "    x = tflearn.max_pool_2d(x, 2, strides=2, name='maxpool4')\n",
    "\n",
    "    x = tflearn.conv_2d(x, 512, 3, activation='relu', scope='conv5_1')\n",
    "    x = tflearn.conv_2d(x, 512, 3, activation='relu', scope='conv5_2')\n",
    "    x = tflearn.conv_2d(x, 512, 3, activation='relu', scope='conv5_3')\n",
    "    x = tflearn.max_pool_2d(x, 2, strides=2, name='maxpool5')\n",
    "\n",
    "    x = tflearn.fully_connected(x, 4096, activation='relu', scope='fc6')\n",
    "    x = tflearn.dropout(x, 0.5, name='dropout1')\n",
    "\n",
    "    x = tflearn.fully_connected(x, 4096, activation='relu', scope='fc7')\n",
    "    x = tflearn.dropout(x, 0.5, name='dropout2')\n",
    "\n",
    "    x = tflearn.fully_connected(x, num_class, activation='softmax', scope='fc8')\n",
    "    x = regression(x, optimizer='adam',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   learning_rate=0.001)\n",
    "\n",
    "    return x\n",
    "\n",
    "# Training\n",
    "model = tflearn.DNN(vgg16(NUM_CLASS), checkpoint_path='checkpoint/model_{}'.format(MODEL_NAME),\n",
    "                    max_checkpoints=1, tensorboard_verbose=0, tensorboard_dir=\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Run id: VGG16_basic\n",
      "Log directory: log/\n",
      "---------------------------------\n",
      "Training samples: 9000\n",
      "Validation samples: 1000\n",
      "--\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[32,64,227,227]\n\t [[Node: conv1_1/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_arg_input/X_0_1/_71, conv1_1/W/read)]]\n\t [[Node: Accuracy/Mean/_79 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_200_Accuracy/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'conv1_1/Conv2D', defined at:\n  File \"c:\\python35\\lib\\runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\python35\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\python35\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\python35\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\python35\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"c:\\python35\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"c:\\python35\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"c:\\python35\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"c:\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\python35\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\python35\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\python35\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2808, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-6e2f5341cfec>\", line 43, in <module>\n    model = tflearn.DNN(vgg16(NUM_CLASS), checkpoint_path='checkpoint/model_{}'.format(MODEL_NAME),\n  File \"<ipython-input-7-6e2f5341cfec>\", line 6, in vgg16\n    x = tflearn.conv_2d(x, 64, 3, activation='relu', scope='conv1_1')\n  File \"c:\\python35\\lib\\site-packages\\tflearn\\layers\\conv.py\", line 99, in conv_2d\n    inference = tf.nn.conv2d(incoming, W, strides, padding)\n  File \"c:\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 399, in conv2d\n    data_format=data_format, name=name)\n  File \"c:\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"c:\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"c:\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,64,227,227]\n\t [[Node: conv1_1/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_arg_input/X_0_1/_71, conv1_1/W/read)]]\n\t [[Node: Accuracy/Mean/_79 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_200_Accuracy/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mc:\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python35\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,64,227,227]\n\t [[Node: conv1_1/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_arg_input/X_0_1/_71, conv1_1/W/read)]]\n\t [[Node: Accuracy/Mean/_79 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_200_Accuracy/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-bbe8e85150a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model.fit(X[:10000], Y[:10000], n_epoch=10, validation_set=0.1, shuffle=True,\n\u001b[0;32m      2\u001b[0m         \u001b[0mshow_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msnapshot_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         snapshot_step=500, run_id=MODEL_NAME)\n\u001b[0m",
      "\u001b[1;32mc:\\python35\\lib\\site-packages\\tflearn\\models\\dnn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X_inputs, Y_targets, n_epoch, validation_set, show_metric, batch_size, shuffle, snapshot_epoch, snapshot_step, excl_trainops, validation_batch_size, run_id, callbacks)\u001b[0m\n\u001b[0;32m    214\u001b[0m                          \u001b[0mexcl_trainops\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexcl_trainops\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                          \u001b[0mrun_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m                          callbacks=callbacks)\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python35\\lib\\site-packages\\tflearn\\helpers\\trainer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, feed_dicts, n_epoch, val_feed_dicts, show_metric, snapshot_step, snapshot_epoch, shuffle_all, dprep_dict, daug_dict, excl_trainops, run_id, callbacks)\u001b[0m\n\u001b[0;32m    336\u001b[0m                                                        \u001b[1;33m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_checkpoint_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0msnapshot_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m                                                        \u001b[0msnapshot_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m                                                        show_metric)\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m                             \u001b[1;31m# Update training state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python35\\lib\\site-packages\\tflearn\\helpers\\trainer.py\u001b[0m in \u001b[0;36m_train\u001b[1;34m(self, training_step, snapshot_epoch, snapshot_step, show_metric)\u001b[0m\n\u001b[0;32m    815\u001b[0m         \u001b[0mtflearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         _, train_summ_str = self.session.run([self.train, self.summ_op],\n\u001b[1;32m--> 817\u001b[1;33m                                              feed_batch)\n\u001b[0m\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m         \u001b[1;31m# Retrieve loss value from summary string\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mc:\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1152\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,64,227,227]\n\t [[Node: conv1_1/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_arg_input/X_0_1/_71, conv1_1/W/read)]]\n\t [[Node: Accuracy/Mean/_79 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_200_Accuracy/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'conv1_1/Conv2D', defined at:\n  File \"c:\\python35\\lib\\runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\python35\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\python35\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\python35\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\python35\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"c:\\python35\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"c:\\python35\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"c:\\python35\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"c:\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\python35\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\python35\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\python35\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2808, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-6e2f5341cfec>\", line 43, in <module>\n    model = tflearn.DNN(vgg16(NUM_CLASS), checkpoint_path='checkpoint/model_{}'.format(MODEL_NAME),\n  File \"<ipython-input-7-6e2f5341cfec>\", line 6, in vgg16\n    x = tflearn.conv_2d(x, 64, 3, activation='relu', scope='conv1_1')\n  File \"c:\\python35\\lib\\site-packages\\tflearn\\layers\\conv.py\", line 99, in conv_2d\n    inference = tf.nn.conv2d(incoming, W, strides, padding)\n  File \"c:\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 399, in conv2d\n    data_format=data_format, name=name)\n  File \"c:\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"c:\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"c:\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,64,227,227]\n\t [[Node: conv1_1/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_arg_input/X_0_1/_71, conv1_1/W/read)]]\n\t [[Node: Accuracy/Mean/_79 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_200_Accuracy/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "model.fit(X[:10000], Y[:10000], n_epoch=10, validation_set=0.1, shuffle=True,\n",
    "        show_metric=True, batch_size=32, snapshot_epoch=False,\n",
    "        snapshot_step=500, run_id=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = load_train_data(resize_pics=(32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, Y = train_data[:, 0], train_data[:, 1]\n",
    "X = np.array([i for i in X])\n",
    "Y = np.array([i for i in Y])\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"ResNet_basic\"\n",
    "NUM_CLASS = 2\n",
    "# Residual blocks\n",
    "# 32 layers: n=5, 56 layers: n=9, 110 layers: n=18\n",
    "BLOCK = 5\n",
    "\n",
    "def resnet(num_class):\n",
    "    # Building 'Residual Network'\n",
    "    \n",
    "    # Real-time data augmentation\n",
    "    img_aug = tflearn.ImageAugmentation()\n",
    "    img_aug.add_random_flip_leftright()\n",
    "    img_aug.add_random_crop([32, 32], padding=4)\n",
    "\n",
    "    # Building Residual Network\n",
    "    net = tflearn.input_data(shape=[None, 32, 32, 3],\n",
    "                             data_augmentation=img_aug)\n",
    "    net = tflearn.conv_2d(net, 16, 3, regularizer='L2', weight_decay=0.0001)\n",
    "    net = tflearn.residual_block(net, BLOCK, 16)\n",
    "    net = tflearn.residual_block(net, 1, 32, downsample=True)\n",
    "    net = tflearn.residual_block(net, BLOCK-1, 32)\n",
    "    net = tflearn.residual_block(net, 1, 64, downsample=True)\n",
    "    net = tflearn.residual_block(net, BLOCK-1, 64)\n",
    "    net = tflearn.batch_normalization(net)\n",
    "    net = tflearn.activation(net, 'relu')\n",
    "    net = tflearn.global_avg_pool(net)\n",
    "    \n",
    "    # Regression\n",
    "    net = tflearn.fully_connected(net, num_class, activation='softmax')\n",
    "    mom = tflearn.Momentum(0.1, lr_decay=0.1, decay_step=32000, staircase=True)\n",
    "    net = tflearn.regression(net, optimizer=mom,\n",
    "                             loss='categorical_crossentropy')\n",
    "    \n",
    "    return net\n",
    "\n",
    "# Training\n",
    "model = tflearn.DNN(resnet(NUM_CLASS), checkpoint_path='model_{}'.format(MODEL_NAME),\n",
    "                    max_checkpoints=5, tensorboard_verbose=3, tensorboard_dir=\"log\")\n",
    "\n",
    "if False:\n",
    "    model.fit(X, Y, n_epoch=10, validation_set=0.1,\n",
    "              snapshot_epoch=False, snapshot_step=500,\n",
    "              show_metric=True, batch_size=128, shuffle=True,\n",
    "              run_id=MODEL_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
