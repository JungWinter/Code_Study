{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Neural Network in 11 Lines of Python\n",
    "\n",
    "## 참고 블로그\n",
    "- [11줄의 파이썬 코드로 뉴럴 네트워크 만들기(한글)](http://ddanggle.github.io/ml/ai/cs/2016/07/16/11lines.html)\n",
    "- [A Neural Network in 11 Lines of Python(영어)](http://iamtrask.github.io/2015/07/12/basic-python-network/)\n",
    "\n",
    "> 영어 원본 페이지는 링크가 깨졌는지 조회되지 않는다  \n",
    "지금은 또 되네 불안정한가보다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 원하는 것\n",
    "|$x_0$|$x_1$|$x_2$|$y$|\n",
    "|:-:|:-:|:-:|:-:|\n",
    "|0|0|1|0|\n",
    "|1|1|1|1|\n",
    "|1|0|1|1|\n",
    "|0|1|1|0|\n",
    "\n",
    "jupyter로 렌더링된 결과가 마음에 안든다. / _ \\ 테이블이 안이뻐..  \n",
    "시키지도 않은 중앙정렬은 왜해.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원본 예제에서는 `nonlin`이 `sigmoid`함수이며 `deriv`값이 `True`일 경우에는 미분된 `sigmoid`함수로 동작한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nonlin(x, deriv=False):\n",
    "    if deriv:\n",
    "        return x * (1-x)\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "밑바닥 부터 시작하는 딥러닝 책을 참고해 `sigmoid`함수를 분리하였다.  \n",
    "`sigmoid_grad`라는 미분된 `sigmoid`의 함수는 해석적으로 구하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid_grad(x):\n",
    "    return (1 - sigmoid(x)) * sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape : (4, 3)\n"
     ]
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [0, 0, 1],\n",
    "    [0, 1, 1],\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 1],\n",
    "])\n",
    "print(\"X.shape :\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expectable output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y.shape : (4, 1)\n"
     ]
    }
   ],
   "source": [
    "Y = np.array([[0, 0, 1, 1]]).T\n",
    "print(\"Y.shape :\", Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0.shape : (3, 1)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "W0 = 2 * np.random.random((3, 1)) - 1\n",
    "print(\"W0.shape :\", W0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "랜덤 시드를 고정해 항상 같은 값이 나오도록 한다.  \n",
    "가중치를 `mean of 0` 으로 초기화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning step\n",
    "`X @ W0`은 `np.dot(X, W0)`과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처음 Y1 : [[ 0.2689864   0.36375058  0.23762817  0.3262757 ]]\n",
      "최종 Y1 : [[  7.21568063e-04   4.80986190e-04   9.99592413e-01   9.99388522e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(\"처음 Y1 : {}\".format(sigmoid(X @ W0).T))\n",
    "for i in range(10000):\n",
    "    # forward propagation\n",
    "    A0 = X @ W0\n",
    "    Y1 = sigmoid(A0)\n",
    "    \n",
    "    # 예측한 것과 정답을 비교해 error를 산출\n",
    "    E = Y - Y1\n",
    "    delta = E * sigmoid_grad(Y1)\n",
    "    \n",
    "    # 갱신\n",
    "    W0 += X.T @ delta\n",
    "print(\"최종 Y1 : {}\".format(Y1.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최종 Y1 : [[  `7.2e-04   4.8e-04   9.9e-01   9.9e-01`]]\n",
    "은  \n",
    "최종 Y1 : [[  `0   0   1   1`]] 와 거의 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처음 Y1 : [[ 0.2689864   0.36375058  0.23762817  0.3262757 ]]\n",
      "최종 Y1 : [[  7.21568063e-04   4.80986190e-04   9.99592413e-01   9.99388522e-01]]\n",
      "최종 W0 : [[ 15.03841089  -0.40582887  -7.23346225]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# function 선언은 생략\n",
    "\n",
    "X = np.array([\n",
    "    [0, 0, 1],\n",
    "    [0, 1, 1],\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 1],\n",
    "])\n",
    "Y = np.array([[0, 0, 1, 1]]).T\n",
    "\n",
    "np.random.seed(1)\n",
    "def learn():\n",
    "    W0 = 2 * np.random.random((3, 1)) - 1\n",
    "    print(\"처음 Y1 : {}\".format(sigmoid(X @ W0).T))\n",
    "    for i in range(10000):\n",
    "        # forward propagation\n",
    "        A0 = X @ W0  # (4 x 3) @ (3 x 1) = (4 x 1)\n",
    "        Y1 = sigmoid(A0)  # 정답 추측\n",
    "\n",
    "        # 예측한 것과 정답을 비교해 error를 산출\n",
    "        E = Y - Y1\n",
    "\n",
    "        # 에러와 나아갈 방향을 곱한다\n",
    "        delta = E * sigmoid_grad(Y1)  # (4 x 1) * (4 x 1)은 각 요소간의 곱셈\n",
    "\n",
    "        # 갱신\n",
    "        W0 += X.T @ delta  # 학습률이 존재하지 않음\n",
    "    print(\"최종 Y1 : {}\".format(Y1.T))\n",
    "    print(\"최종 W0 : {}\".format(W0.T))\n",
    "\n",
    "learn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 해석\n",
    "`delta = E * gradient_sigmoid(Y1)`부분은 **미분에 의해 가중치가 계산된 에러**라고 생각할 수 있다.\n",
    "최종 `W0`에서 보듯 `Y`를 결정하는데 $x_0$이 제일 중요하다는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 한계\n",
    "웨이트를 기준으로 히든 레이어가 존재하지 않는 1층짜리 뉴럴 네트워크기 때문에 `XOR`에 대해선 동작하지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처음 Y1 : [[ 0.3067574   0.17919499  0.22958471  0.12818018]]\n",
      "최종 Y1 : [[ 0.5  0.5  0.5  0.5]]\n",
      "최종 W0 : [[ -2.35922393e-16  -2.35922393e-16   1.52655666e-16]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [0, 0, 1],\n",
    "    [0, 1, 1],\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 1],\n",
    "])\n",
    "Y = np.array([[0, 1, 1, 0]]).T\n",
    "\n",
    "learn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래서 중간에 히든 레이어를 추가시켜보겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처음 Y2 : [[ 0.55416188  0.56688831  0.58149581  0.59194271]]\n",
      "> 에러 E2 : 0.4994\n",
      "> 에러 E2 : 0.4975\n",
      "> 에러 E2 : 0.4794\n",
      "> 에러 E2 : 0.1239\n",
      "> 에러 E2 : 0.0609\n",
      "> 에러 E2 : 0.0386\n",
      "> 에러 E2 : 0.0280\n",
      "> 에러 E2 : 0.0220\n",
      "> 에러 E2 : 0.0182\n",
      "> 에러 E2 : 0.0156\n",
      "최종 Y2 : [[ 0.01074817  0.98524772  0.98418738  0.01332049]]\n",
      "최종 W1 : [[ -7.72686346 -17.31045592 -16.10551481  33.61994748]]\n"
     ]
    }
   ],
   "source": [
    "def learn2():\n",
    "    # hidden layer의 노드 수를 4개로 설정했다.\n",
    "    W0 = 2 * np.random.random((3, 4)) - 1\n",
    "    W1 = 2 * np.random.random((4, 1)) - 1\n",
    "    \n",
    "    print(\"처음 Y2 : {}\".format(sigmoid(sigmoid(X @ W0) @ W1).T))\n",
    "    for i in range(10000):\n",
    "        # forward propagation\n",
    "        A0 = X @ W0  # (4 x 3) @ (3 x 4) = (4 x 4)\n",
    "        Y1 = sigmoid(A0)  # (4 x 4)\n",
    "        A1 = Y1 @ W1  # (4 x 4) @ (4 x 1) = (4 x 1)\n",
    "        Y2 = sigmoid(A1)  # (4 x 1)\n",
    "\n",
    "        # 예측한 것과 정답을 비교해 error를 산출\n",
    "        E2 = Y - Y2\n",
    "        if i % 1000 == 0:\n",
    "            print(\"> 에러 E2 : {:.4f}\".format(np.mean(np.abs(E2))))\n",
    "\n",
    "        # 에러와 나아갈 방향을 곱한다\n",
    "        delta2 = E2 * sigmoid_grad(Y2)  # (4 x 1)\n",
    "        \n",
    "        # 이부분이 바로 역전파 부분\n",
    "        # 히든레이어의 오차와 delta값을 정한다.\n",
    "        E1 = delta2 @ W1.T  # (4 x 1) @ (1 x 4) = (4 x 4)\n",
    "        delta1 = E1 * sigmoid_grad(Y1)  # (4 x 4)\n",
    "\n",
    "        # 갱신\n",
    "        W1 += Y1.T @ delta2\n",
    "        W0 += X.T @ delta1\n",
    "    print(\"최종 Y2 : {}\".format(Y2.T))\n",
    "    print(\"최종 W1 : {}\".format(W1.T))\n",
    "\n",
    "learn2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "성공적으로 XOR문제를 예측했다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
